{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, classification_report\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize the features\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(211)\n",
    "\n",
    "# Using gridsearch to choose a optimal model for the knn\n",
    "# Parameters to tune are: k, weights\n",
    "gs = GridSearchCV(estimator=neighbors.KNeighborsClassifier(p=2,metric='minkowski'),\n",
    "                  param_grid=[{'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21], 'weights':['uniform','distance']}],\n",
    "                  scoring='accuracy', # Specifying multiple metrics for evaluation\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8482152785499834\n",
      "{'n_neighbors': 11, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# print the best score and parameters for the best model\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parameters generated from the best KNN model to compute the mean and variance of acuracy using cross-validation\n",
    "clf3 = neighbors.KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                                        metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
    "                                        weights='uniform')\n",
    "\n",
    "scores=cross_val_score(clf3, X_train_std, y_train, scoring='accuracy', cv=5)\n",
    "\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
    "                                      np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the classifiers\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n",
    "all_clf = [clf1, clf2, clf3]\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in zip([clf1, clf2, clf3], clf_labels): #For all classifiers \n",
    "    scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=5,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
    "          % (scores.mean(), scores.std(), label))\n",
    "\n",
    "colors = [ 'orange', 'blue', 'green']      #Colors for visualization\n",
    "linestyles = [':', '--', '-.', '-']        #Line styles for visualization\n",
    "for clf, label, clr, ls in zip(all_clf,\n",
    "               clf_labels, colors, linestyles):\n",
    "\n",
    "    # assuming the label of the positive class is 1 and data is normalized\n",
    "    y_pred = clf.fit(X_train,\n",
    "                     y_train).predict_proba(X_test)[:, 1] # Make predictions based on the classifiers\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) \n",
    "    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.2f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')    # Where to place the legend\n",
    "plt.plot([0, 1], [0, 1], # Visualize random classifier\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])   #limits for x axis\n",
    "plt.ylim([-0.1, 1.1])   #limits for y axis\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "\n",
    "#plt.savefig('ROC_all_classifiers', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
